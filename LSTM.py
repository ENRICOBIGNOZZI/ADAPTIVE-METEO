{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPhHzsAC3wwu",
        "outputId": "bd288cfe-a01c-4992-d35f-6584606a3a49"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Ztj2c95Io7lg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "f894f37f-50fc-49d6-82b9-32ccff18c6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-f\n",
            "/root/.local/share/jupyter/runtime/kernel-dc01353b-257d-4803-ac87-b69539d6139e.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-5cb411214c78>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mlen_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_to_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mfeature_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0mstation_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from math import sqrt\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import os\n",
        "import time\n",
        "import pickle as pc\n",
        "import typing\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from functools import partial\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "from torch.utils.data import Sampler\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "#Classe che serve a selezionare indici da cui prendere sequenze tali per cui non ci siano misure mancanti\n",
        "class SpecificIndicesSampler(Sampler):\n",
        "    def __init__(self, indices):\n",
        "        self.indices = indices\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "#EarlyStopping è una procedura basata sull'andamento della Loss function\n",
        "#Se la loss function di validazione, per un tot di epoche consecutive, non migliora, allora il training termina\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model, path):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, path):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "#Metriche varie utili nella fase di training, validation e testing\n",
        "def MAE(pred, true):\n",
        "    return np.mean(np.abs(pred - true))\n",
        "def MSE(pred, true):\n",
        "    return np.mean((pred - true) ** 2)\n",
        "def RMSE(pred, true):\n",
        "    return np.sqrt(MSE(pred, true))\n",
        "def MAPE(pred, true):\n",
        "    return np.mean(np.abs((pred - true) / true))\n",
        "def MSPE(pred, true):\n",
        "    return np.mean(np.square((pred - true) / true))\n",
        "\n",
        "\n",
        "\n",
        "csv_file = sys.argv[1]\n",
        "len_to_predict = sys.argv[2]\n",
        "feature_to_predict = sys.argv[3]\n",
        "station_to_predict = sys.argv[4]\n",
        "\n",
        "last_column = feature_to_predict + \"_STA{}\".format(station_to_predict)\n",
        "print(last_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xQYNVTL7ApQ-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_file).dropna()#carico i dati in un dataframe\n",
        "df['DATE'] = pd.to_datetime(df['DATE'])\n",
        "df['hour']=df['DATE'].dt.hour\n",
        "df['month']=df.DATE.dt.month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "S26C54Pi5f8-",
        "outputId": "e29b1ba7-fae2-4c8c-8497-a60fb3942172"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      DATE  TEMP_STA0  TEMP_STA1  TEMP_STA2  TEMP_STA3  \\\n",
              "0      2017-12-31 23:00:00        0.4       -0.5       -0.2        0.8   \n",
              "1      2017-12-31 23:10:00        0.4       -0.5       -0.1        0.5   \n",
              "2      2017-12-31 23:20:00        0.5       -0.4        0.1        0.4   \n",
              "3      2017-12-31 23:30:00        0.6       -0.6        0.1        0.5   \n",
              "4      2017-12-31 23:40:00        0.5       -0.6        0.0        0.5   \n",
              "...                    ...        ...        ...        ...        ...   \n",
              "288011 2023-06-30 21:10:00       18.3       14.7       19.0       16.8   \n",
              "288012 2023-06-30 21:20:00       18.2       14.6       19.2       16.7   \n",
              "288013 2023-06-30 21:30:00       18.4       14.6       18.9       16.7   \n",
              "288014 2023-06-30 21:40:00       18.6       14.6       18.6       16.7   \n",
              "288015 2023-06-30 21:50:00       18.6       14.4       18.6       16.7   \n",
              "\n",
              "         HUM_STA0   HUM_STA1   HUM_STA2   HUM_STA3  HUM_STA4  ...  PRO_X_STA3  \\\n",
              "0        3.549326   3.548452   3.330457   3.500666  2.840725  ...    0.376199   \n",
              "1        3.553188   3.566890   3.355219   3.440777  2.802474  ...    0.941700   \n",
              "2        3.571351   3.586537   3.378451   3.423564  2.794110  ...    0.709204   \n",
              "3        3.550733   3.559492   3.378451   3.417761  2.761485  ...    0.777847   \n",
              "4        3.548359   3.562732   3.387315   3.351254  2.752909  ...    0.874468   \n",
              "...           ...        ...        ...        ...       ...  ...         ...   \n",
              "288011  12.179787  10.452045  13.258120  11.977863  6.944306  ...    0.501484   \n",
              "288012  12.206934  10.383656  13.331684  11.900560  6.896224  ...   -0.075700   \n",
              "288013  12.300469  10.373273  13.213610  11.900560  6.849126  ...    0.135991   \n",
              "288014  12.539815  10.372230  13.016501  11.900560  6.848442  ...    0.555917   \n",
              "288015  12.485938  10.235779  12.922179  11.900560  6.848442  ...    0.540914   \n",
              "\n",
              "        PRO_X_STA4  PRO_Y_STA0  PRO_Y_STA1  PRO_Y_STA2  PRO_Y_STA3  \\\n",
              "0        -0.188340   -0.066964   -0.149575    0.031813    0.613901   \n",
              "1        -0.337945    1.227706    0.007632   -0.166338    1.102589   \n",
              "2         0.004608    0.590669   -0.010139    0.038470   -0.324699   \n",
              "3        -0.344881    0.571708    0.177309    0.390154   -0.452718   \n",
              "4        -0.320937    0.016720    0.156449   -0.322610   -0.316553   \n",
              "...            ...         ...         ...         ...         ...   \n",
              "288011   -1.181061   -0.483188   -0.799239    1.098390   -0.329414   \n",
              "288012   -0.370637    0.500331   -0.073610    0.616411    0.065342   \n",
              "288013    0.378884    0.481452    0.042265   -0.815330   -0.584386   \n",
              "288014    0.057564    0.368997    0.370988   -0.979365    0.225735   \n",
              "288015   -0.044588    0.428935    0.293335   -0.832921    0.444311   \n",
              "\n",
              "        PRO_Y_STA4  hour  month  TEMP_STA4  \n",
              "0         0.220518    23     12       -3.5  \n",
              "1         0.844922    23     12       -3.6  \n",
              "2         0.659984    23     12       -3.6  \n",
              "3         0.732910    23     12       -3.7  \n",
              "4         1.083466    23     12       -3.7  \n",
              "...            ...   ...    ...        ...  \n",
              "288011    0.543227    21      6        8.6  \n",
              "288012   -0.708963    21      6        8.5  \n",
              "288013    0.128245    21      6        8.4  \n",
              "288014    0.998342    21      6        8.4  \n",
              "288015    0.397507    21      6        8.4  \n",
              "\n",
              "[288016 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdc0c0b0-5565-40e7-9256-7f404f250fbd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>TEMP_STA0</th>\n",
              "      <th>TEMP_STA1</th>\n",
              "      <th>TEMP_STA2</th>\n",
              "      <th>TEMP_STA3</th>\n",
              "      <th>HUM_STA0</th>\n",
              "      <th>HUM_STA1</th>\n",
              "      <th>HUM_STA2</th>\n",
              "      <th>HUM_STA3</th>\n",
              "      <th>HUM_STA4</th>\n",
              "      <th>...</th>\n",
              "      <th>PRO_X_STA3</th>\n",
              "      <th>PRO_X_STA4</th>\n",
              "      <th>PRO_Y_STA0</th>\n",
              "      <th>PRO_Y_STA1</th>\n",
              "      <th>PRO_Y_STA2</th>\n",
              "      <th>PRO_Y_STA3</th>\n",
              "      <th>PRO_Y_STA4</th>\n",
              "      <th>hour</th>\n",
              "      <th>month</th>\n",
              "      <th>TEMP_STA4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-12-31 23:00:00</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>3.549326</td>\n",
              "      <td>3.548452</td>\n",
              "      <td>3.330457</td>\n",
              "      <td>3.500666</td>\n",
              "      <td>2.840725</td>\n",
              "      <td>...</td>\n",
              "      <td>0.376199</td>\n",
              "      <td>-0.188340</td>\n",
              "      <td>-0.066964</td>\n",
              "      <td>-0.149575</td>\n",
              "      <td>0.031813</td>\n",
              "      <td>0.613901</td>\n",
              "      <td>0.220518</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>-3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-12-31 23:10:00</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3.553188</td>\n",
              "      <td>3.566890</td>\n",
              "      <td>3.355219</td>\n",
              "      <td>3.440777</td>\n",
              "      <td>2.802474</td>\n",
              "      <td>...</td>\n",
              "      <td>0.941700</td>\n",
              "      <td>-0.337945</td>\n",
              "      <td>1.227706</td>\n",
              "      <td>0.007632</td>\n",
              "      <td>-0.166338</td>\n",
              "      <td>1.102589</td>\n",
              "      <td>0.844922</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>-3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-12-31 23:20:00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.571351</td>\n",
              "      <td>3.586537</td>\n",
              "      <td>3.378451</td>\n",
              "      <td>3.423564</td>\n",
              "      <td>2.794110</td>\n",
              "      <td>...</td>\n",
              "      <td>0.709204</td>\n",
              "      <td>0.004608</td>\n",
              "      <td>0.590669</td>\n",
              "      <td>-0.010139</td>\n",
              "      <td>0.038470</td>\n",
              "      <td>-0.324699</td>\n",
              "      <td>0.659984</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>-3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-12-31 23:30:00</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3.550733</td>\n",
              "      <td>3.559492</td>\n",
              "      <td>3.378451</td>\n",
              "      <td>3.417761</td>\n",
              "      <td>2.761485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777847</td>\n",
              "      <td>-0.344881</td>\n",
              "      <td>0.571708</td>\n",
              "      <td>0.177309</td>\n",
              "      <td>0.390154</td>\n",
              "      <td>-0.452718</td>\n",
              "      <td>0.732910</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>-3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-12-31 23:40:00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3.548359</td>\n",
              "      <td>3.562732</td>\n",
              "      <td>3.387315</td>\n",
              "      <td>3.351254</td>\n",
              "      <td>2.752909</td>\n",
              "      <td>...</td>\n",
              "      <td>0.874468</td>\n",
              "      <td>-0.320937</td>\n",
              "      <td>0.016720</td>\n",
              "      <td>0.156449</td>\n",
              "      <td>-0.322610</td>\n",
              "      <td>-0.316553</td>\n",
              "      <td>1.083466</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>-3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288011</th>\n",
              "      <td>2023-06-30 21:10:00</td>\n",
              "      <td>18.3</td>\n",
              "      <td>14.7</td>\n",
              "      <td>19.0</td>\n",
              "      <td>16.8</td>\n",
              "      <td>12.179787</td>\n",
              "      <td>10.452045</td>\n",
              "      <td>13.258120</td>\n",
              "      <td>11.977863</td>\n",
              "      <td>6.944306</td>\n",
              "      <td>...</td>\n",
              "      <td>0.501484</td>\n",
              "      <td>-1.181061</td>\n",
              "      <td>-0.483188</td>\n",
              "      <td>-0.799239</td>\n",
              "      <td>1.098390</td>\n",
              "      <td>-0.329414</td>\n",
              "      <td>0.543227</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>8.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288012</th>\n",
              "      <td>2023-06-30 21:20:00</td>\n",
              "      <td>18.2</td>\n",
              "      <td>14.6</td>\n",
              "      <td>19.2</td>\n",
              "      <td>16.7</td>\n",
              "      <td>12.206934</td>\n",
              "      <td>10.383656</td>\n",
              "      <td>13.331684</td>\n",
              "      <td>11.900560</td>\n",
              "      <td>6.896224</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.075700</td>\n",
              "      <td>-0.370637</td>\n",
              "      <td>0.500331</td>\n",
              "      <td>-0.073610</td>\n",
              "      <td>0.616411</td>\n",
              "      <td>0.065342</td>\n",
              "      <td>-0.708963</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288013</th>\n",
              "      <td>2023-06-30 21:30:00</td>\n",
              "      <td>18.4</td>\n",
              "      <td>14.6</td>\n",
              "      <td>18.9</td>\n",
              "      <td>16.7</td>\n",
              "      <td>12.300469</td>\n",
              "      <td>10.373273</td>\n",
              "      <td>13.213610</td>\n",
              "      <td>11.900560</td>\n",
              "      <td>6.849126</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135991</td>\n",
              "      <td>0.378884</td>\n",
              "      <td>0.481452</td>\n",
              "      <td>0.042265</td>\n",
              "      <td>-0.815330</td>\n",
              "      <td>-0.584386</td>\n",
              "      <td>0.128245</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>8.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288014</th>\n",
              "      <td>2023-06-30 21:40:00</td>\n",
              "      <td>18.6</td>\n",
              "      <td>14.6</td>\n",
              "      <td>18.6</td>\n",
              "      <td>16.7</td>\n",
              "      <td>12.539815</td>\n",
              "      <td>10.372230</td>\n",
              "      <td>13.016501</td>\n",
              "      <td>11.900560</td>\n",
              "      <td>6.848442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555917</td>\n",
              "      <td>0.057564</td>\n",
              "      <td>0.368997</td>\n",
              "      <td>0.370988</td>\n",
              "      <td>-0.979365</td>\n",
              "      <td>0.225735</td>\n",
              "      <td>0.998342</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>8.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288015</th>\n",
              "      <td>2023-06-30 21:50:00</td>\n",
              "      <td>18.6</td>\n",
              "      <td>14.4</td>\n",
              "      <td>18.6</td>\n",
              "      <td>16.7</td>\n",
              "      <td>12.485938</td>\n",
              "      <td>10.235779</td>\n",
              "      <td>12.922179</td>\n",
              "      <td>11.900560</td>\n",
              "      <td>6.848442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.540914</td>\n",
              "      <td>-0.044588</td>\n",
              "      <td>0.428935</td>\n",
              "      <td>0.293335</td>\n",
              "      <td>-0.832921</td>\n",
              "      <td>0.444311</td>\n",
              "      <td>0.397507</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>8.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>288016 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdc0c0b0-5565-40e7-9256-7f404f250fbd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdc0c0b0-5565-40e7-9256-7f404f250fbd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdc0c0b0-5565-40e7-9256-7f404f250fbd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dcc2333d-2325-4e8d-8e2f-8b6052ee576a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcc2333d-2325-4e8d-8e2f-8b6052ee576a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dcc2333d-2325-4e8d-8e2f-8b6052ee576a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "col0= ['DATE', 'TEMP_STA0', 'TEMP_STA1', 'TEMP_STA2', 'TEMP_STA3', 'TEMP_STA4', 'HUM_STA0',\n",
        "       'HUM_STA1', 'HUM_STA2', 'HUM_STA3', \"HUM_STA4\", 'PRESS_STA0',\n",
        "       'PRESS_STA1', 'PRESS_STA2', 'PRESS_STA3', 'PRESS_STA4', 'PRO_X_STA0',\n",
        "       'PRO_X_STA1', 'PRO_X_STA2', 'PRO_X_STA3', 'PRO_X_STA4', 'PRO_Y_STA0',\n",
        "       'PRO_Y_STA1', 'PRO_Y_STA2', 'PRO_Y_STA3', 'PRO_Y_STA4', 'hour', 'month']#seleziono le colonne relative alle features da utilizzare\n",
        "\n",
        "\n",
        "\n",
        "df=df[col0]\n",
        "\n",
        "df[\"PRED_COL\"] = df[last_column]\n",
        "df.drop(columns = last_column, inplace = True)\n",
        "df.rename(columns={\"PRED_COL\": last_column}, inplace=True)\n",
        "co = df.columns[1:]\n",
        "df = df.reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oMoRqZvz5piW"
      },
      "outputs": [],
      "source": [
        "#Qui si esegue il controllo sui dati mancanti\n",
        "#Si chiede che di una sequenza di dati presa dal dataframe, questa non presenti dati mancanti\n",
        "\n",
        "desired_interval = 1008                 #Deve essere più maggiore o uguale alla lunghezza della sequenza in input più il tempo nel futuro da prevedere (cioè desired_interval >= seq_len + pred_len)\n",
        "df[\"DATE\"]=pd.to_datetime(df[\"DATE\"])\n",
        "desired_duration = timedelta(days=7)\n",
        "good_starts = []\n",
        "for i in range(df.shape[0]-desired_interval):                                      #Crea vettore di indici buoni per selezionare sequenze senza salti\n",
        "  if df[\"DATE\"][i+desired_interval]-df[\"DATE\"][i] == desired_duration:\n",
        "    good_starts.append(df.index[i])\n",
        "fea = df.shape[1]-1\n",
        "good_starts_train = good_starts[0:int(len(good_starts)*0.7)]            #Divide il vettore good_starts in indici iniziali di train, validation e di test\n",
        "good_starts_vali = good_starts[int(len(good_starts)*0.7):int(len(good_starts)*0.9)]\n",
        "good_starts_vali = [l for l in good_starts_vali if l>(good_starts_train[-1]+desired_interval+1)]\n",
        "good_starts_test = good_starts[int(len(good_starts)*0.9):int(1*len(good_starts))]\n",
        "good_starts_test = [l for l in good_starts_test if l>(good_starts_vali[-1]+desired_interval+1)]  #Train, validation e test non possono sovrapporsi, dunque c'è un embargo fra i tre set\n",
        "\n",
        "shuffled_list = good_starts_train.copy()                                                        #Fa lo shuffle del train\n",
        "random.shuffle(shuffled_list)\n",
        "tr = shuffled_list\n",
        "va = good_starts_vali\n",
        "te =  good_starts_test\n",
        "gs=[tr,va,te]                                            #gs è un array che contiene a sua volta tre array di indici, uno con indici da cui leggere sequenze per train, e gli altri due per vali e test\n",
        "df=df[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "lW0P1PJ6qFJd"
      },
      "outputs": [],
      "source": [
        "#'forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
        "#Per l'obbiettivo preposto si utilizzano più features per prevederne una sola, per cui l'opzione usata è sempre e solo MS.\n",
        "class Dataset():\n",
        "    def __init__(self, root_path=None, flag='train', size=None,\n",
        "                 features='MS',target=last_column, scale=True, timeenc=0, freq='10m'):\n",
        "\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info sugli input\n",
        "        # size:lista contenente [seq_len, label_len, pred_len]\n",
        "        # features: stringa che specifica il tipo di task di previsione\n",
        "        # target: stringa che specifica la variabile target\n",
        "        # scale: se True si effettua lo scaling dei dati con MinMax Scaler, altrimenti False\n",
        "        # timeenc: intero indicante il tipo di encoding temporale\n",
        "        # freq: stringa che specifica la frequenza\n",
        "        if size == None:\n",
        "            print(\"size è none. Forse ci sono problemi\")\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.pred_len = size[1]\n",
        "        # init\n",
        "        assert flag in ['train', 'val','test']\n",
        "        type_map = {'train': 0, 'val': 1, 'test':2} #Flag che specifica il tipo di splitting diverso per ogni set\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.root_path = root_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self): #Questo metodo effettua una lettura e un preprocessing dei dati (ossia uno scaling)\n",
        "        self.scaler = MinMaxScaler() #Scaler che normalizza i dati tra 0 e 1\n",
        "        df_raw = df\n",
        "        #border1s e border2s sono liste usate per definire gli estremi degli intervalli sulla base del tipo di splitting\n",
        "        #in questo caso non è necessario definire diversi borders per train, validation e test in quanto gli indici da cui\n",
        "        #prendere le sequenze sono già specificati nel Sampler (classe all'inizio del codice)\n",
        "\n",
        "        #Nel caso si volesse non utilizzare il sampler sarebbe tuttavia necessario specificare i borders sulla base della divisione in train, validation e test\n",
        "        border1s = [0,\n",
        "                    0,\n",
        "                    0]\n",
        "        border2s = [int(len(df_raw)*1),\n",
        "                    int(len(df_raw)*1),\n",
        "                    int(len(df_raw)*1)]\n",
        "\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            stop_index = good_starts_train[-1]+desired_interval\n",
        "            train_data = df_data.iloc[:stop_index + 1]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "            self.scaler.fit(train_data[self.target].values.reshape(-1, 1)) #Cosi' poi da andare a denormalizzare le previsioni per valutare le prestazioni sul test\n",
        "        else:\n",
        "            data = df_data.values\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "\n",
        "\n",
        "    def __getitem__(self, index): #Metodo usato per recuperare una specifica sequenza di dati dal dataset dato un certo indice (parte, insieme al Sampler, del DataLoader)\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[s_begin:s_end+self.pred_len]\n",
        "\n",
        "        return seq_x,seq_y\n",
        "\n",
        "    def __len__(self): #Ritorna il numero totale di sequenze nel dataset\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data): # Effettua lo scaling inverso dei dati nel caso si sia scelto di riscalarli nel preprocessing (si fa per il test)\n",
        "        return self.scaler.inverse_transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "K-4FVjLOC81Z"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    \"\"\"Layer comprising a convolution layer followed by LSTM and dense layers.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        seq_len,\n",
        "        pred_len,\n",
        "        n_features,\n",
        "        batch_size,\n",
        "        hidden,\n",
        "        nlayers,\n",
        "        dropout\n",
        "    ):\n",
        "        super(Model, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len=pred_len\n",
        "        self.hidden=hidden\n",
        "        self.n_features=n_features\n",
        "        self.batch_size=batch_size\n",
        "        self.nlayers=nlayers\n",
        "        self.dropout = dropout                           #Modello con layer LSTM e batch normalization alternati\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(self.n_features)\n",
        "        self.lstm1 = nn.LSTM(self.n_features, self.hidden, num_layers=self.nlayers, batch_first=True, dropout=self.dropout)\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden)\n",
        "        self.lstm2 = nn.LSTM(self.hidden, self.hidden * 2, num_layers=self.nlayers, batch_first=True, dropout=self.dropout)\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden * 2)\n",
        "        self.dense1 = nn.Linear(self.hidden * 2, self.hidden * 1)\n",
        "        self.bn5 = nn.BatchNorm1d(self.hidden * 1)\n",
        "        self.dense2 = nn.Linear(self.hidden * 1, 1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"input: BxSxF\n",
        "        con B=Batch_size\n",
        "            S=Lunghezza sequenza\n",
        "            F=Numero di features\n",
        "        \"\"\"\n",
        "        inputs=self.bn1(inputs.permute(0,2,1)).permute(0,2,1)                #I permute servono per fare le batch normalization appropriatamente\n",
        "        lstm1_out,_ = self.lstm1(inputs)\n",
        "        lstm1_out=self.bn2(lstm1_out.permute(0,2,1)).permute(0,2,1)\n",
        "        lstm2_out,_ = self.lstm2(lstm1_out)\n",
        "        lstm2_out=self.bn3(lstm2_out.permute(0,2,1)).permute(0,2,1)\n",
        "        dense1_out = self.dense1(lstm2_out)\n",
        "        dense1_out=self.bn5(dense1_out.permute(0,2,1)).permute(0,2,1)\n",
        "        dense2_out = self.dense2(dense1_out)\n",
        "        dense2_out = dense2_out[:, -self.pred_len:,:]        #Alla fine si seleziona soltanto l'ultimo elemento in uscita dal layer LSTM\n",
        "        return dense2_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ncMo7ZYcslKO"
      },
      "outputs": [],
      "source": [
        "class DNNModel(object):\n",
        "    def __init__(self,batch_size,seq_len,lstm_units,lr,weight_decay, nlayers,dropout,epochs_early_stopping=20, pred_len = len_to_predict):\n",
        "        self.embed='fixed'\n",
        "        self.batch_size=batch_size\n",
        "        self.freq='10m'\n",
        "        self.pred_len= pred_len   #Questo è un input da riga di comando\n",
        "        self.seq_len=seq_len\n",
        "\n",
        "        self.n_features=27       #Features in ingresso\n",
        "        self.lstm_units=lstm_units       #Dimensione hidden di output per LSTM\n",
        "        self.train_epochs=500                #Numero epoche\n",
        "        self.patience_early_stopping = 10    #Pazienza EarlyStopping\n",
        "        self.patience_scheduler = 2          #Pazienza scheduler (Spiegato dopo)\n",
        "        self.features='MS'\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.checkpoints='./checkpoints/'  #Serve a salvare i pesi relativi alla migliore prestazione del modello\n",
        "        self.lr=lr                         #Learning rate\n",
        "        self.nlayers=nlayers                #Numero di stacks di lstm (ogni layer lstm può processare le sequenze su più livelli, andando a carpire correlazioni più sottili)\n",
        "        self.weight_decay = weight_decay    #Serve a tenere sotto controllo overfitting riducendo i pesi man mano che il training avanza\n",
        "        self.dropout=dropout                #Serve a prevenire overfitting annullando l'effetto di alcuni pesi a caso in training\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def data_provider(self,flag):\n",
        "        data_dict = {'ETTh1': Dataset}    #Dizionario che serve a prendere il dataset\n",
        "        Data = data_dict['ETTh1']\n",
        "\n",
        "        if flag == 'val':            #Condizioni poste sulla base della fase dell'algoritmo (per train, validation, test)\n",
        "            shuffle_flag = False\n",
        "            drop_last =  True\n",
        "            batch_size =  1\n",
        "            freq = self.freq\n",
        "            v_s = 1                     #Indice vs serve a selezionare una serie di indici da usare dal vettore gs per il Sampler\n",
        "\n",
        "        elif flag == 'test':\n",
        "            shuffle_flag = False\n",
        "            drop_last =  True\n",
        "            batch_size =  1\n",
        "            freq = self.freq\n",
        "            v_s = 2\n",
        "\n",
        "        else:\n",
        "            shuffle_flag= False\n",
        "            drop_last =  True\n",
        "            batch_size =self.batch_size\n",
        "            freq = self.freq\n",
        "            v_s = 0\n",
        "\n",
        "        data_set = Data(\n",
        "            flag=flag,\n",
        "            size=[self.seq_len, self.pred_len],         #Definizione del dataset e del DataLoader\n",
        "            freq=self.freq\n",
        "        )\n",
        "\n",
        "        data_loader = DataLoader(\n",
        "            data_set,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=shuffle_flag,\n",
        "            num_workers=0,\n",
        "            drop_last=drop_last,\n",
        "            sampler=SpecificIndicesSampler(gs[v_s])     #Sampler accede al vettore di indici buoni che ho definito (o train o validation) e sceglie indici da li cosi da non avere salti\n",
        "            )                                           #in una singola sequenza. Non si può mettere Sampler e shuffle insieme, quindi lo shuffle è effettuato prima\n",
        "        return data_set, data_loader\n",
        "\n",
        "    #Crea il modello da addestrare\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Model(seq_len=self.seq_len,pred_len=self.pred_len,n_features=self.n_features,batch_size=self.batch_size, hidden=self.lstm_units,nlayers=self.nlayers,dropout=self.dropout).to(self.device)\n",
        "        return model\n",
        "\n",
        "    #Seleziona ottimizzatore\n",
        "    def _select_optimizer(self):\n",
        "        model_optim = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
        "        return model_optim\n",
        "\n",
        "    #Seleziona la funzione di loss\n",
        "    def _select_criterion(self):\n",
        "        criterion = nn.MSELoss() # Altrimenti nn.HuberLoss(reduction='mean', delta=1.0), altrimenti nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def _get_data(self, flag):\n",
        "        data_set, data_loader = self.data_provider(flag)\n",
        "        return data_set, data_loader\n",
        "\n",
        "\n",
        "    #Fase di validation\n",
        "\n",
        "    def vali(self, vali_data, vali_loader, criterion):\n",
        "        total_loss = []\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "          for i, (batch_x,batch_y) in enumerate(vali_loader):\n",
        "            batch_x = batch_x.float().to(self.device)\n",
        "            batch_y = batch_y.float().to(self.device)\n",
        "            outputs = self.model(batch_x)\n",
        "            f_dim = -1 if(self.features == 'MS' or self.features =='S')  else 0\n",
        "            outputs = outputs[:, -1:, f_dim:]     #Prende ultimo elemento predetto (in realtà questo è gia fatto nella rete) dall'output della rete\n",
        "            batch_y = batch_y[:, -1:, f_dim:].to(self.device)  #Prende ultimo valore della sequenza, vale a dire quello che si vuole prevedere, dalla sequenza presa dal dataset di validation\n",
        "            pred = outputs.detach().cpu()\n",
        "            true = batch_y.detach().cpu()\n",
        "            loss = criterion(pred, true)\n",
        "\n",
        "            total_loss.append(loss)\n",
        "\n",
        "        total_loss = np.average(total_loss)\n",
        "        self.model.train()\n",
        "        return total_loss\n",
        "\n",
        "    #Fase di train\n",
        "\n",
        "    def train(self,setting):\n",
        "        train_data, train_loader = self._get_data(flag='train')\n",
        "        vali_data, vali_loader = self._get_data(flag='val')\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "        path = os.path.join(self.checkpoints, setting)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        time_now = time.time()\n",
        "        train_steps = len(train_loader)\n",
        "        early_stopping = EarlyStopping(patience=self.patience_early_stopping, verbose=True)\n",
        "        model_optim = self._select_optimizer()\n",
        "        criterion = self._select_criterion()  #Utilizzo delle funzioni precedentemente definite per dare al modello impostazioni di training\n",
        "\n",
        "        #Scheduler decide di abbassare il learning rate (cioè di permettere meno mobilità ai pesi) quando c'è uno stallo nella validation loss\n",
        "        scheduler = ReduceLROnPlateau(model_optim, mode='min', patience=self.patience_scheduler, factor=0.5, verbose=False)\n",
        "\n",
        "        #Training effettivo\n",
        "        for epoch in range(self.train_epochs):\n",
        "            iter_count = 0\n",
        "            train_loss = []\n",
        "            self.model.train()\n",
        "            epoch_time = time.time()\n",
        "            for i, (batch_x, batch_y) in enumerate(train_loader):\n",
        "                iter_count += 1\n",
        "                model_optim.zero_grad()                                   #Zero grad, loss backward, optimizer step sono gli elementi essenziali nella fase di training in torch\n",
        "                batch_x = batch_x.float().to(self.device)                 #In validation e in test NON VENGONO MESSI, perche i pesi sono fissi\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "                outputs = self.model(batch_x)\n",
        "                f_dim = -1 if(self.features == 'MS' or self.features =='S')  else 0    #Tutto simile a ciò che è stato definito in fase di validation\n",
        "                outputs = outputs[:, -1:, f_dim:]\n",
        "                batch_y = batch_y[:, -1:, f_dim:].to(self.device)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "                if (i + 1) % 10000 == 0:\n",
        "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
        "                    speed = (time.time() - time_now) / iter_count\n",
        "                    left_time = speed * ((self.train_epochs - epoch) * train_steps - i)\n",
        "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "                    iter_count = 0\n",
        "                    time_now = time.time()\n",
        "\n",
        "                loss.backward()\n",
        "                model_optim.step()\n",
        "\n",
        "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "            train_loss = np.average(train_loss)\n",
        "            vali_loss= self.vali(vali_data, vali_loader, criterion)                    #Valutazione di validation e di test\n",
        "            scheduler.step(vali_loss)\n",
        "            test_loss = self.vali(test_data, test_loader, criterion)\n",
        "\n",
        "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
        "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
        "\n",
        "            early_stopping(vali_loss, self.model, path)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "        best_model_path = path + '/' + 'checkpoint.pth'\n",
        "        self.model.load_state_dict(torch.load(best_model_path))\n",
        "        return self.model\n",
        "\n",
        "\n",
        "\n",
        "    #Fase di testing indipendente, ossia post-training\n",
        "    #La valutazione di test è stata già fatta per ogni epoca, tuttavia dopo la fine del training, per visualizzare i risultati, si prende il miglior modello salvato\n",
        "    #ossia quello che ha ottenuto la minore loss di validation (non si può decidere sulla base del test in quanto il programma non deve vedere il test in alcun modo)\n",
        "    def vali_test(self, setting, test=True):\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "\n",
        "        if test:\n",
        "            print('loading model')\n",
        "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))  #Carica sul modello i pesi con migliore validation loss\n",
        "\n",
        "        preds = []\n",
        "        trues = []\n",
        "        folder_path = './test_results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y) in enumerate(test_loader):\n",
        "              batch_x = batch_x.float().to(self.device)\n",
        "              batch_y = batch_y.float().to(self.device)\n",
        "              outputs = self.model(batch_x)\n",
        "              f_dim = -1 if(self.features == 'MS' or self.features =='S')  else 0\n",
        "              outputs = outputs[:, -1:, f_dim:]\n",
        "              batch_y = batch_y[:, -1:, f_dim:].to(self.device)\n",
        "              outputs = outputs.detach().cpu().numpy()\n",
        "              batch_y = batch_y.detach().cpu().numpy()\n",
        "              pred = outputs\n",
        "              true = batch_y\n",
        "              preds.append(pred)\n",
        "              trues.append(true)\n",
        "\n",
        "\n",
        "        preds = np.array(preds)                                                #Genera i risultati da poter plottare e visualizzare\n",
        "        trues = np.array(trues)\n",
        "\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
        "\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        return preds,trues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Gh8bdZAjs28Q"
      },
      "outputs": [],
      "source": [
        "def _build_space(): #La funzione genera lo spazio di ricerca per gli iperaparametri da usare nel fine-tuning\n",
        "    space = {\n",
        "        'batch_size': hp.quniform('batch_size', 16, 526, 16),\n",
        "        'seq_len': hp.quniform('seq_len', 10, 100, 1),\n",
        "        'lstm_units': hp.quniform('lstm_units', 16, 256, 16),\n",
        "        'lr': hp.uniform('lr', 0.000000001, 0.01),\n",
        "        'nlayers': hp.quniform('nlayers', 1, 2, 1),\n",
        "        'dropout': hp.uniform('dropout', 0, 0.3),\n",
        "        \"weight_decay\": hp.uniform('weight_decay', 0.000000001, 0.0001),\n",
        "        }\n",
        "    return space\n",
        "\n",
        "\n",
        "\n",
        "def _hyperopt_objective(hyperparameters, trials, trials_file_path, max_evals):#definisce l'obiettivo della minimizzazione per il processo di ottimizzazione degli iperparametri\n",
        "    #info input:\n",
        "    #hyperparameters: dizionario contenente gli iperparametri da valutare\n",
        "    #trials:oggetto che conserva le informazioni rilevanti per il processo di ottimizzazione\n",
        "    #trials_file_path: path del file in cui salvare i trials\n",
        "    #max_evals: numero di valutazioni massimo della funzione di costo\n",
        "    pc.dump(trials, open(trials_file_path, \"wb\"))\n",
        "    setting = '{}'.format('EMANUELE')\n",
        "    print(hyperparameters)\n",
        "    forecaster = DNNModel(batch_size=int(hyperparameters['batch_size']),seq_len=int(hyperparameters['seq_len']),weight_decay=int(hyperparameters['weight_decay']),lstm_units=int(hyperparameters['lstm_units']),nlayers=int(hyperparameters['nlayers']),lr=(hyperparameters['lr']),dropout=(hyperparameters['dropout']))\n",
        "\n",
        "    forecaster.train(setting).to(\"cuda\")\n",
        "    Yp_mean ,Y_test= forecaster.vali_test(setting,test=True)\n",
        "    Y_test = Dataset(flag='test',size=[1,1,1],freq='10m').inverse_transform(Y_test.reshape(-1, Y_test.shape[-1])).flatten()\n",
        "    Yp_mean = Dataset(flag='test',size=[1,1,1],freq='10m').inverse_transform(Yp_mean.reshape(-1, Yp_mean.shape[-1])).flatten()\n",
        "\n",
        "    mae_validation = np.mean(MAE(Yp_mean, Y_test))#calcola la media del mae sul validation set e sul test set\n",
        "    smape_validation = np.mean(RMSE(Yp_mean, Y_test))\n",
        "    differenza=(abs(Yp_mean-Y_test)).flatten()#calcola gli errori in modulo sul test set\n",
        "    print(\"errore max\", max(differenza))#printa il massimo e il minimo dell'errore commesso\n",
        "    print(\"errore min\", min(differenza))\n",
        "    print(\"  MAE: {:.3f} | RMSE: {:.3f} %\".format(mae_validation, smape_validation))\n",
        "    return_values = {'loss': mae_validation, 'MAE test': mae_validation,'RMSE test': smape_validation, 'hyper': hyperparameters,'status': STATUS_OK}#i risultati del processo vengono ritornati tramite un dizionario\n",
        "    if trials.losses()[0] is not None:#la condizione controlla che nell'oggetto trials ci siano effettivamente delle losses. Trials.losses() riporta la lista di loss salvate nel processo di ottimizzazione\n",
        "        MAEVal = trials.best_trial['result']['MAE test']#riporta il miglior valore del MAE durante il processo di ottimizzazione.\n",
        "        sMAPEVal = trials.best_trial['result']['RMSE test']#riporta il miglior valore del RMSE durante il processo di ottimizzazione\n",
        "        parametri = trials.best_trial['result']['hyper']#riporta la migliore scelta di iperparametri\n",
        "\n",
        "        print('\\n\\nTested {}/{} iterations.'.format(len(trials.losses()) - 1,max_evals))\n",
        "        print('Best MAE - Validation Dataset')\n",
        "        print(\"  MAE: {:.3f} | RMSE: {:.3f} %\".format(MAEVal, sMAPEVal))\n",
        "    return return_values\n",
        "\n",
        "def hyperparameter_optimizer(path_hyperparameters_folder=os.path.join('.', 'experimental_files'),\n",
        "                             new_hyperopt=1, max_evals=3):\n",
        "\n",
        "    if not os.path.exists(path_hyperparameters_folder):\n",
        "        os.makedirs(path_hyperparameters_folder)\n",
        "    trials_file_name = 'DNN_hyperparameters'\n",
        "    trials_file_path = os.path.join(path_hyperparameters_folder, trials_file_name)\n",
        "    if new_hyperopt:#Se new_hyperopt è True inizializza un nuovo oggetto trials\n",
        "        trials = Trials()\n",
        "    else:\n",
        "        trials = pc.load(open(trials_file_path, \"rb\"))\n",
        "    space = _build_space()\n",
        "\n",
        "    fmin_objective = partial(_hyperopt_objective, trials=trials, trials_file_path=trials_file_path,\n",
        "                             max_evals=max_evals)\n",
        "    fmin(fmin_objective, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials, verbose=False)#fmin da hyperopt performa l'ottimizzazione utilizzando l'algoritmo Tree-structured Parzen Estimators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "LdZSRLlltdPJ",
        "outputId": "142c1481-d6c5-4fdf-b3fe-549f8af697c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 512.0, 'dropout': 0.048840609118384816, 'lr': 0.00040770143039525834, 'lstm_units': 208.0, 'nlayers': 1.0, 'seq_len': 72.0, 'weight_decay': 5.728155549304076e-05}\n",
            "TEMP_STA4\n",
            "TEMP_STA4\n",
            "TEMP_STA4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-b3bcb70831c0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_hyperparameters_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./experimental_files/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbest_hyperparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_hyperparameters_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_hyperparameters_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_hyperopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_hyperopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-7996c4bb07b5>\u001b[0m in \u001b[0;36mhyperparameter_optimizer\u001b[0;34m(path_hyperparameters_folder, new_hyperopt, max_evals)\u001b[0m\n\u001b[1;32m     61\u001b[0m     fmin_objective = partial(_hyperopt_objective, trials=trials, trials_file_path=trials_file_path,\n\u001b[1;32m     62\u001b[0m                              max_evals=max_evals)\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmin_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#fmin da hyperopt performa l'ottimizzazione utilizzando l'algoritmo Tree-structured Parzen Estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-7996c4bb07b5>\u001b[0m in \u001b[0;36m_hyperopt_objective\u001b[0;34m(hyperparameters, trials, trials_file_path, max_evals)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mforecaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlstm_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lstm_units'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nlayers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dropout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mforecaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mYp_mean\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mforecaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvali_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'10m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-b83e0bb4372a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mmodel_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {} cost time: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepoch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0;31m# call optimizer step pre hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpre_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_global_optimizer_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, args)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# TODO: TorchScript ignores standard type annotation here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;31m# self.record: Optional[\"torch.classes.profiler._RecordFunction\"] = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"torch.classes.profiler._RecordFunction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "new_hyperopt = 1\n",
        "max_evals = 35\n",
        "path_hyperparameters_folder = \"./experimental_files/\"\n",
        "best_hyperparameters=hyperparameter_optimizer(path_hyperparameters_folder=path_hyperparameters_folder,new_hyperopt=new_hyperopt, max_evals=max_evals)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trials_file_name = 'DNN_hyperparameters'\n",
        "trials_file_path = os.path.join(path_hyperparameters_folder, trials_file_name)\n",
        "trials = pc.load(open(trials_file_path, \"rb\"))\n",
        "for trial in trials.trials:\n",
        "    print(trial['result'])"
      ],
      "metadata": {
        "id": "tNTK2CwIQWbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e920b53-520b-4864-daea-ce691d72fc38"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': 'new'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iy2NbxZ1Cs7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}