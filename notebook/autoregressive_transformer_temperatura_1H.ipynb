{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1c97e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "ff1c97e5",
    "outputId": "17b4767b-9e86-4aad-fa9c-b675349116cd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhyperopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin, tpe, hp, Trials, STATUS_OK\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#from MFDFA import MFDFA\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "import pickle as pc\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from functools import partial\n",
    "#from MFDFA import MFDFA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "'''os.environ[\"MLFINLAB_API_KEY\"] = \"2f849d6ab0af7315a1de23309417fb85\"\n",
    "import mlfinlab\n",
    "from mlfinlab.data_structures import standard_data_structures\n",
    "from mlfinlab.labeling.raw_return import raw_return\n",
    "from mlfinlab.sample_weights.attribution import get_weights_by_time_decay\n",
    "from mlfinlab.labeling.trend_scanning import trend_scanning_labels\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlfinlab.util import volatility\n",
    "from mlfinlab.filters import filters\n",
    "from mlfinlab.feature_importance.fingerprint import RegressionModelFingerprint\n",
    "from mlfinlab.labeling import labeling\n",
    "from mlfinlab.networks.almst import ALMST\n",
    "from mlfinlab.networks.dash_graph import DashGraph\n",
    "from mlfinlab.codependence.codependence_matrix import get_distance_matrix\n",
    "from mlfinlab.sample_weights.attribution import get_weights_by_return'''\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def media_mobile(serie_dati, periodi):\n",
    "    medie_mobile = []\n",
    "    for i in range(len(serie_dati) - periodi + 1):\n",
    "        media = sum(serie_dati[i:i+periodi]) / periodi\n",
    "        medie_mobile.append(media)\n",
    "    return medie_mobile\n",
    "\n",
    "file_path = \"dati.csv\"\n",
    "df_raw = pd.read_csv(file_path).reset_index(drop=True)\n",
    "df_raw=df_raw[200:]\n",
    "nomi_colonne_da_salvare = ['DATE', 'VALUE_LT_STA3']\n",
    "df_raw = df_raw.loc[:, nomi_colonne_da_salvare]\n",
    "df_raw.rename(columns={'DATE': 'Date'}, inplace=True)#.reset_index(drop=True)\n",
    "#df_raw = df_raw.iloc[::-1].reset_index(drop=True)\n",
    "#df_raw = df_raw.iloc[::6]\n",
    "df_raw=df_raw[1:].reset_index(drop=True)\n",
    "df_raw.to_csv('emanuele.csv', index=False)#.reset_index(drop=True)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eqwT0o5_xS1i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eqwT0o5_xS1i",
    "outputId": "5345fff9-17d1-4bc5-d910-40160f553f5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-7c693b89-6b5d-4afb-8596-61cc2cd84b94\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>VALUE_LT_STA3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-15 09:30:00</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-15 09:40:00</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-15 09:50:00</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-15 10:00:00</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-15 10:10:00</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-15 10:20:00</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-15 10:30:00</td>\n",
       "      <td>25.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-06-15 10:40:00</td>\n",
       "      <td>26.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-06-15 10:50:00</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-06-15 11:00:00</td>\n",
       "      <td>26.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-06-15 11:10:00</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-06-15 11:20:00</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-06-15 11:30:00</td>\n",
       "      <td>27.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-06-15 11:40:00</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-06-15 11:50:00</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-06-15 12:00:00</td>\n",
       "      <td>27.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-06-15 12:10:00</td>\n",
       "      <td>28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-06-15 12:20:00</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-06-15 12:30:00</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-06-15 12:40:00</td>\n",
       "      <td>28.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-06-15 12:50:00</td>\n",
       "      <td>29.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-06-15 13:00:00</td>\n",
       "      <td>29.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-06-15 13:10:00</td>\n",
       "      <td>29.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-06-15 13:20:00</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-06-15 13:30:00</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-06-15 13:40:00</td>\n",
       "      <td>29.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-06-15 13:50:00</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-06-15 14:00:00</td>\n",
       "      <td>30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-06-15 14:10:00</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-06-15 14:20:00</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-06-15 14:30:00</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-06-15 14:40:00</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-06-15 14:50:00</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-06-15 15:00:00</td>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-06-15 15:10:00</td>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-06-15 15:20:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2021-06-15 15:30:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021-06-15 15:40:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021-06-15 15:50:00</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021-06-15 16:00:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2021-06-15 16:10:00</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2021-06-15 16:20:00</td>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2021-06-15 16:30:00</td>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2021-06-15 16:40:00</td>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2021-06-15 16:50:00</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2021-06-15 17:00:00</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2021-06-15 17:10:00</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2021-06-15 17:20:00</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2021-06-15 17:30:00</td>\n",
       "      <td>30.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2021-06-15 17:40:00</td>\n",
       "      <td>30.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c693b89-6b5d-4afb-8596-61cc2cd84b94')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-1d5bccb4-317e-488c-a8d6-04971a6e56d2\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d5bccb4-317e-488c-a8d6-04971a6e56d2')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-1d5bccb4-317e-488c-a8d6-04971a6e56d2 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7c693b89-6b5d-4afb-8596-61cc2cd84b94 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7c693b89-6b5d-4afb-8596-61cc2cd84b94');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   Date  VALUE_LT_STA3\n",
       "0   2021-06-15 09:30:00           24.6\n",
       "1   2021-06-15 09:40:00           24.8\n",
       "2   2021-06-15 09:50:00           25.0\n",
       "3   2021-06-15 10:00:00           25.1\n",
       "4   2021-06-15 10:10:00           25.4\n",
       "5   2021-06-15 10:20:00           25.4\n",
       "6   2021-06-15 10:30:00           25.8\n",
       "7   2021-06-15 10:40:00           26.1\n",
       "8   2021-06-15 10:50:00           26.5\n",
       "9   2021-06-15 11:00:00           26.7\n",
       "10  2021-06-15 11:10:00           26.9\n",
       "11  2021-06-15 11:20:00           27.2\n",
       "12  2021-06-15 11:30:00           27.3\n",
       "13  2021-06-15 11:40:00           27.5\n",
       "14  2021-06-15 11:50:00           27.8\n",
       "15  2021-06-15 12:00:00           27.9\n",
       "16  2021-06-15 12:10:00           28.2\n",
       "17  2021-06-15 12:20:00           28.4\n",
       "18  2021-06-15 12:30:00           28.7\n",
       "19  2021-06-15 12:40:00           28.9\n",
       "20  2021-06-15 12:50:00           29.1\n",
       "21  2021-06-15 13:00:00           29.3\n",
       "22  2021-06-15 13:10:00           29.1\n",
       "23  2021-06-15 13:20:00           29.2\n",
       "24  2021-06-15 13:30:00           29.5\n",
       "25  2021-06-15 13:40:00           29.6\n",
       "26  2021-06-15 13:50:00           29.8\n",
       "27  2021-06-15 14:00:00           30.1\n",
       "28  2021-06-15 14:10:00           30.3\n",
       "29  2021-06-15 14:20:00           30.4\n",
       "30  2021-06-15 14:30:00           30.6\n",
       "31  2021-06-15 14:40:00           30.7\n",
       "32  2021-06-15 14:50:00           30.6\n",
       "33  2021-06-15 15:00:00           30.8\n",
       "34  2021-06-15 15:10:00           30.9\n",
       "35  2021-06-15 15:20:00           31.0\n",
       "36  2021-06-15 15:30:00           31.0\n",
       "37  2021-06-15 15:40:00           31.0\n",
       "38  2021-06-15 15:50:00           31.1\n",
       "39  2021-06-15 16:00:00           31.0\n",
       "40  2021-06-15 16:10:00           31.1\n",
       "41  2021-06-15 16:20:00           30.9\n",
       "42  2021-06-15 16:30:00           30.8\n",
       "43  2021-06-15 16:40:00           30.8\n",
       "44  2021-06-15 16:50:00           30.7\n",
       "45  2021-06-15 17:00:00           30.6\n",
       "46  2021-06-15 17:10:00           30.5\n",
       "47  2021-06-15 17:20:00           30.5\n",
       "48  2021-06-15 17:30:00           30.2\n",
       "49  2021-06-15 17:40:00           30.2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b228a8f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "b228a8f2",
    "outputId": "280720f8-1bc9-46ab-dc48-c46f001a3f0f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'correlation_matrix = df_raw.drop(\"DATE\",axis=1).corr(method=\\'pearson\\')\\ncustom_matrix = get_distance_matrix(correlation_matrix, metric=\\'angular\\')\\ngraph = ALMST(custom_matrix, \\'distance\\')\\ndash_graph = DashGraph(graph)\\nserver = dash_graph.get_server()\\nserver.run_server()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''correlation_matrix = df_raw.drop(\"DATE\",axis=1).corr(method='pearson')\n",
    "custom_matrix = get_distance_matrix(correlation_matrix, metric='angular')\n",
    "graph = ALMST(custom_matrix, 'distance')\n",
    "dash_graph = DashGraph(graph)\n",
    "server = dash_graph.get_server()\n",
    "server.run_server()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944de910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "944de910",
    "outputId": "ff758f8a-7796-409f-f094-7894d65686d2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'df_raw = pd.read_csv(\\'emanuele.csv\\').drop(\\'Date\\', axis=1)\\nscaler =StandardScaler()\\n\\nX = df_raw.drop(\\'VALUE_LT_STA6\\', axis=1)[:-1]\\nX= pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\\n\\ny = df_raw[\\'VALUE_LT_STA6\\'].shift(1)[1:]\\nreg = RandomForestRegressor(n_estimators=100, random_state=42)\\nreg = reg.fit(X, y)\\n# Create the fingerprint model\\nreg_fingerprint = RegressionModelFingerprint()\\n# Fit the fingerprint model\\n_ = reg_fingerprint.fit(\\n     reg,\\n     X,\\n     num_values=20,)\\n# Get linear non-linear effects and pairwise effects\\nlinear_effect, non_linear_effect, pair_wise_effect = reg_fingerprint.get_effects()\\n# Plot the results\\nfig = reg_fingerprint.plot_effects(sort_by=\"non_lin\")\\nfig.show()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_raw = pd.read_csv('emanuele.csv').drop('Date', axis=1)\n",
    "scaler =StandardScaler()\n",
    "\n",
    "X = df_raw.drop('VALUE_LT_STA6', axis=1)[:-1]\n",
    "X= pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "y = df_raw['VALUE_LT_STA6'].shift(1)[1:]\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg = reg.fit(X, y)\n",
    "# Create the fingerprint model\n",
    "reg_fingerprint = RegressionModelFingerprint()\n",
    "# Fit the fingerprint model\n",
    "_ = reg_fingerprint.fit(\n",
    "     reg,\n",
    "     X,\n",
    "     num_values=20,)\n",
    "# Get linear non-linear effects and pairwise effects\n",
    "linear_effect, non_linear_effect, pair_wise_effect = reg_fingerprint.get_effects()\n",
    "# Plot the results\n",
    "fig = reg_fingerprint.plot_effects(sort_by=\"non_lin\")\n",
    "fig.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba8485d",
   "metadata": {
    "id": "fba8485d"
   },
   "outputs": [],
   "source": [
    "class Dataset():#'forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "    def __init__(self, root_path=None, flag='train', size=None,\n",
    "                 features='MS',target='target', scale=True, timeenc=0, freq='m'):\n",
    "\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        if size == None:\n",
    "            print(\"size Ã¨ none. Forse ci sono problemi\")\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.root_path = root_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler =StandardScaler()\n",
    "        df_raw = pd.read_csv('emanuele.csv')\n",
    "        print(df_raw)\n",
    "        border1s = [0, int(len(df_raw)*0.99)- self.seq_len, int(len(df_raw)*0.88)- self.seq_len]#[0, len(df_raw)-200- self.seq_len, len(df_raw)-100 - self.seq_len]#[0, int(len(df_raw)*0.95)- self.seq_len, int(len(df_raw)*0.98) - self.seq_len]\n",
    "        border2s = [int(len(df_raw)*0.99) , int(len(df_raw)*1), int(len(df_raw)*9)]#[len(df_raw)-200 , len(df_raw) -100, int(len(df_raw))]#[int(len(df_raw)*0.95) , int(len(df_raw)*0.98), int(len(df_raw)*1)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "            self.scaler.fit(train_data['VALUE_LT_STA3'].values.reshape(-1, 1))\n",
    "            #data=data.values\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        df_stamp = df_raw[['Date']][border1:border2]\n",
    "        df_stamp['Date'] = pd.to_datetime(df_stamp.Date)\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.Date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['minute'] = df_stamp.Date.apply(lambda row: row.minute, 10)\n",
    "            df_stamp['hour'] = df_stamp.Date.apply(lambda row: row.hour, 1)\n",
    "            data_stamp = df_stamp.drop(labels=['Date'], axis=1).values\n",
    "            print(df_stamp)\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(df_stamp['Date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n",
    "\n",
    "class Dataset_Pred(Dataset):\n",
    "    def __init__(self, root_path=None, flag='train', size=None,\n",
    "                 features='MS',\n",
    "                 target='target', scale=True, timeenc=0, freq='m'):\n",
    "        if size == None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "        assert flag in ['pred']\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv('emanuele.csv')\n",
    "        border1 = len(df_raw) - self.seq_len\n",
    "        border2 = len(df_raw)\n",
    "\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            self.scaler.fit(df_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "            self.scaler.fit(df_data['VALUE_LT_STA3'].values.reshape(-1, 1))\n",
    "            data=data.values\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        tmp_stamp = df_raw[['Date']][border1:border2]\n",
    "        tmp_stamp['Date'] = pd.to_datetime(tmp_stamp.Date)\n",
    "        pred_dates = pd.date_range(tmp_stamp.Date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
    "        df_stamp = pd.DataFrame(columns=['Date'])\n",
    "        df_stamp.Date = list(tmp_stamp.Date.values) + list(pred_dates[1:])\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.Date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['minute'] = df_stamp.Date.apply(lambda row: row.minute, 10)\n",
    "            df_stamp['hour'] = df_stamp.Date.apply(lambda row: row.hour, 1)\n",
    "            data_stamp = df_stamp.drop(labels=['Date'], axis=1).values\n",
    "            print(df_stamp)\n",
    "            data_stamp = df_stamp.drop(labels=['Date'], axis=1).values\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(df_stamp['Date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        print(pred_dates)\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101edbca",
   "metadata": {
    "id": "101edbca"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='m'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "        print(\"qui non dovrei entrare\")\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'B': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='m'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        hour_size = 24\n",
    "        weekday_size = 8\n",
    "        day_size = 32\n",
    "        minute_size = 61\n",
    "        month_size = 13\n",
    "\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "\n",
    "        self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        hour_x = self.hour_embed(x[:, :, 2])\n",
    "        minute_x = self.minute_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "        return minute_x + month_x+hour_x\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='m', dropout=0.1):# questa va cambiata in base alla tipologia\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq)# if embed_type == 'timeF' else TimeFeatureEmbedding(\n",
    "            #d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cuda\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "class ProbMask():\n",
    "    def __init__(self, B, H, L, index, scores, device=\"cuda\"):\n",
    "        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n",
    "        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n",
    "        indicator = _mask_ex[torch.arange(B)[:, None, None],\n",
    "                    torch.arange(H)[None, :, None],\n",
    "                    index, :].to(device)\n",
    "        self._mask = indicator.view(scores.shape).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "class DSAttention(nn.Module):\n",
    "    '''De-stationary Attention'''\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(DSAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / sqrt(E)\n",
    "\n",
    "        tau = 1.0 if tau is None else tau.unsqueeze(1).unsqueeze(1)  # B x 1 x 1 x 1\n",
    "        delta = 0.0 if delta is None else delta.unsqueeze(1).unsqueeze(1)  # B x 1 x 1 x S\n",
    "\n",
    "        # De-stationary Attention, rescaling pre-softmax score with learned de-stationary factors\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys) * tau + delta\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), A)\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau, delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i==0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    " \n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    '''\n",
    "    MLP to learn the De-stationary factors\n",
    "    '''\n",
    "    def __init__(self, enc_in, seq_len, hidden_dims, hidden_layers, output_dim, kernel_size=3):\n",
    "        super(Projector, self).__init__()\n",
    "\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.series_conv = nn.Conv1d(in_channels=seq_len, out_channels=1, kernel_size=kernel_size, padding=padding, padding_mode='circular', bias=False)\n",
    "\n",
    "        layers = [nn.Linear(2 * enc_in, hidden_dims[0]), nn.ReLU()]\n",
    "        for i in range(hidden_layers-1):\n",
    "            layers += [nn.Linear(hidden_dims[i], hidden_dims[i+1]), nn.ReLU()]\n",
    "\n",
    "        layers += [nn.Linear(hidden_dims[-1], output_dim, bias=False)]\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, stats):\n",
    "        # x:     B x S x E\n",
    "        # stats: B x 1 x E\n",
    "        # y:     B x O\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.series_conv(x)          # B x 1 x E\n",
    "        x = torch.cat([x, stats], dim=1) # B x 2 x E\n",
    "        x = x.view(batch_size, -1) # B x 2E\n",
    "        y = self.backbone(x)       # B x O\n",
    "        return y\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Non-stationary Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, pred_len,seq_len,label_len,output_attention='store_true',enc_in=1,dec_in=1,d_model=512,embed='timeF',\n",
    "                 freq='m',dropout=0.05,factor=1,e_layers=1,n_heads=16,d_ff=2048,p_hidden_dims=[128, 128],\n",
    "                 p_hidden_layers=2,activation='gelu',d_layers=1,c_out=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.output_attention = output_attention\n",
    "        self.enc_in=enc_in\n",
    "        self.dec_in=dec_in\n",
    "        self.d_model=d_model\n",
    "        self.embed=embed\n",
    "        self.freq=freq\n",
    "        self.dropout=dropout\n",
    "        self.factor=factor\n",
    "        self.e_layers=e_layers\n",
    "        self.n_heads=n_heads\n",
    "        self.d_ff=d_ff\n",
    "        self.p_hidden_dims=p_hidden_dims\n",
    "        self.p_hidden_layers=p_hidden_layers\n",
    "        self.activation=activation\n",
    "        self.d_layers=d_layers\n",
    "        self.c_out=c_out\n",
    "\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq,\n",
    "                                           dropout)\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq,\n",
    "                                           dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=output_attention), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(True, factor, attention_dropout=dropout, output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(False, factor, attention_dropout=dropout, output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation,\n",
    "                )\n",
    "                for l in range(self.d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "        self.tau_learner   = Projector(enc_in=enc_in, seq_len=seq_len, hidden_dims=p_hidden_dims, hidden_layers=p_hidden_layers, output_dim=1)\n",
    "        self.delta_learner = Projector(enc_in=enc_in, seq_len=seq_len, hidden_dims=p_hidden_dims, hidden_layers=p_hidden_layers, output_dim=seq_len)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "\n",
    "        x_raw = x_enc.clone().detach()\n",
    "        # Normalization\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach() # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach() # B x 1 x E\n",
    "        x_enc = x_enc / std_enc\n",
    "        x_dec_new = torch.cat([x_enc[:, -self.label_len: , :], torch.zeros_like(x_dec[:, -self.pred_len:, :])], dim=1).to(x_enc.device).clone()\n",
    "\n",
    "        tau = self.tau_learner(x_raw, std_enc).exp()     # B x S x E, B x 1 x E -> B x 1, positive scalar\n",
    "        delta = self.delta_learner(x_raw, mean_enc)      # B x S x E, B x 1 x E -> B x S\n",
    "\n",
    "        # Model Inference\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask, tau=tau, delta=delta)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec_new, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask, tau=tau, delta=delta)\n",
    "\n",
    "        # De-normalization\n",
    "        dec_out = dec_out * std_enc + mean_enc\n",
    "        output=dec_out[:, -self.pred_len:, :]\n",
    "        if self.output_attention:\n",
    "            return output, attns\n",
    "        else:\n",
    "            return output # [B, L, D]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551a83df",
   "metadata": {
    "id": "551a83df"
   },
   "outputs": [],
   "source": [
    "class DNNModel(object):\n",
    "    def __init__(self,batch_size, epochs_early_stopping=20):\n",
    "        self.embed='fixed'\n",
    "        self.batch_size=batch_size\n",
    "        self.freq='10m'\n",
    "        self.num_workers=0\n",
    "        self.pred_len=6*1\n",
    "        self.label_len=6\n",
    "        self.seq_len=1000\n",
    "        self.model = self._build_model()\n",
    "        self.use_amp=False\n",
    "        self.train_epochs=1000\n",
    "        self.features='MS'\n",
    "        self.output_attention=True\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.checkpoints='./checkpoints/'\n",
    "        self.lr=0.001\n",
    "\n",
    "\n",
    "    def data_provider(self,flag):\n",
    "        data_dict = {\n",
    "            'ETTh1': Dataset\n",
    "        }\n",
    "        Data = data_dict['ETTh1']\n",
    "        timeenc = 0 #if self.embed == 'timeF' else 1\n",
    "        if flag == 'test':\n",
    "            shuffle_flag = False\n",
    "            drop_last = False\n",
    "            batch_size = 1\n",
    "            freq = self.freq\n",
    "        elif flag == 'pred':\n",
    "            shuffle_flag = False\n",
    "            drop_last = False\n",
    "            batch_size =  1\n",
    "            freq = self.freq\n",
    "            Data = Dataset_Pred\n",
    "        elif flag == 'val':\n",
    "            shuffle_flag = False\n",
    "            drop_last = False\n",
    "            batch_size =  1\n",
    "            freq = self.freq\n",
    "        else:\n",
    "            shuffle_flag=True\n",
    "            drop_last = True\n",
    "            batch_size =self.batch_size\n",
    "            freq = self.freq\n",
    "\n",
    "        data_set = Data(\n",
    "            flag=flag,\n",
    "            size=[self.seq_len, self.label_len,self.pred_len],\n",
    "            freq=self.freq\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=drop_last)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Model(pred_len=self.pred_len,seq_len=self.seq_len,label_len=self.label_len,output_attention=True).to(\"cuda\")\n",
    "        return model\n",
    "    \n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.lr)#,weight_decay=0.0005\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.HuberLoss(reduction='mean', delta=1.0)#nn.MSELoss()#nn.CrossEntropyLoss()#nn.BCELoss()#nn.BCEWithLogitsLoss() #nn.NLLLoss()#nn.HuberLoss(reduction='mean', delta=1.0)#nn.MSELoss()#nn.BCELoss()#nn.L1Loss()#nn.HuberLoss(reduction='mean', delta=1.0)#nn.MSELoss()#nn.HuberLoss(reduction='mean', delta=1.0)#nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = self.data_provider(flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion):\n",
    "        total_loss = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.pred_len:, :]).float()#qui penso di dover mettere l'output\n",
    "                dec_inp = torch.cat([batch_y[:, :self.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if (self.features == 'MS' or self.features =='S')  else 0\n",
    "                outputs = outputs[:, -self.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "                total_loss.append(loss)\n",
    "\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "    def train(self,setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "        #test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "        path = os.path.join(self.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=100, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "        scheduler = ReduceLROnPlateau(model_optim, mode='min', patience=3, factor=0.5, verbose=False)\n",
    "        if self.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        for epoch in range(self.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                if self.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                        f_dim = -1 if (self.features == 'MS' or self.features =='S')  else 0\n",
    "                        outputs = outputs[:, -self.pred_len:, f_dim:]\n",
    "                        batch_y = batch_y[:, -self.pred_len:, f_dim:].to(self.device)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        train_loss.append(loss.item())\n",
    "                else:\n",
    "                    if self.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    f_dim = -1 if(self.features == 'MS' or self.features =='S')  else 0\n",
    "                    outputs = outputs[:, -self.pred_len:, f_dim:]\n",
    "                    #print(outputs)\n",
    "                    batch_y = batch_y[:, -self.pred_len:, f_dim:].to(self.device)\n",
    "                    #print(batch_y )\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * ((self.train_epochs - epoch) * train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                if self.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss= self.vali(vali_data, vali_loader, criterion)\n",
    "\n",
    "            scheduler.step(vali_loss)\n",
    "            #test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            #print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "            #    epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "        return self.model\n",
    "\n",
    "    def vali_test(self, setting, test=True):\n",
    "        test_data, test_loader = self._get_data(flag='val')\n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if (self.features == 'MS' or self.features =='S') else 0\n",
    "                outputs = outputs[:, -self.pred_len:, f_dim:]\n",
    "                #outputs =torch.argmax(outputs, dim=1)\n",
    "                batch_y = batch_y[:, -self.pred_len:, f_dim:].to(self.device)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                batch_y = batch_y.detach().cpu().numpy()\n",
    "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        #mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "        #print('mse:{}, mae:{}'.format(mse, mae))\n",
    "        #f = open(\"result.txt\", 'a')\n",
    "        #f.write(setting + \"  \\n\")\n",
    "        #f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "        #f.write('\\n')\n",
    "        #f.write('\\n')\n",
    "        #f.close()\n",
    "\n",
    "        #np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "        #np.save(folder_path + 'pred.npy', preds)\n",
    "        #np.save(folder_path + 'true.npy', trues)\n",
    "\n",
    "        return preds,trues\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, setting, load=True):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "\n",
    "        if load:\n",
    "            path = os.path.join(self.checkpoints, setting)\n",
    "            best_model_path = path + '/' + 'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros([batch_y.shape[0], self.pred_len, batch_y.shape[2]]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                preds.append(pred)\n",
    "                #print(preds)\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "        # result save\n",
    "        #folder_path = './results/' + setting + '/'\n",
    "        #if not os.path.exists(folder_path):\n",
    "        #    os.makedirs(folder_path)\n",
    "\n",
    "        #np.save(folder_path + 'real_prediction.npy', preds)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a75c56",
   "metadata": {
    "id": "b3a75c56"
   },
   "outputs": [],
   "source": [
    "def _build_space():\n",
    "    space = {\n",
    "        'batch_size': hp.quniform('batch_size',20,21,1),\n",
    "        }\n",
    "    return space\n",
    "\n",
    "\n",
    "\n",
    "def _hyperopt_objective(hyperparameters, trials, trials_file_path, max_evals):\n",
    "\n",
    "    #print(hyperparameters)\n",
    "\n",
    "\n",
    "    pc.dump(trials, open(trials_file_path, \"wb\"))\n",
    "    setting = '{}'.format('EMANUELE')\n",
    "\n",
    "    forecaster = DNNModel(\n",
    "        batch_size=int(hyperparameters['batch_size'])\n",
    "                     )\n",
    "\n",
    "    forecaster.train(setting).to(\"cuda\")\n",
    "    Yp_mean ,Y_test= forecaster.test(setting,test=True)\n",
    "\n",
    "\n",
    "    #Y_test = Dataset().inverse_transform(Y_test.reshape(-1, Y_test.shape[-1])).flatten()\n",
    "    #Yp_mean = Dataset().inverse_transform(Yp_mean.reshape(-1, Yp_mean.shape[-1])).flatten()\n",
    "    #print(\"Yp_mean\",Yp_mean)\n",
    "    #print(\"Y_test\",Y_test)\n",
    "\n",
    "    mae_validation = np.mean(MAE(Yp_mean, Y_test))\n",
    "    smape_validation = np.mean(sMAPE(Y_test, Yp_mean))*100\n",
    "    return_values = {'loss': mae_validation, 'MAE Val': mae_validation,'sMAPE Val': smape_validation,\n",
    "                     'status': STATUS_OK}\n",
    "\n",
    "    if trials.losses()[0] is not None:\n",
    "        MAEVal = trials.best_trial['result']['MAE Val']\n",
    "        sMAPEVal = trials.best_trial['result']['sMAPE Val']\n",
    "\n",
    "        print('\\n\\nTested {}/{} iterations.'.format(len(trials.losses()) - 1,\n",
    "              max_evals))\n",
    "        print('Best MAE - Validation Dataset')\n",
    "        print(\"  MAE: {:.1f} | sMAPE: {:.2f} %\".format(MAEVal, sMAPEVal))\n",
    "    return return_values\n",
    "\n",
    "def hyperparameter_optimizer(path_hyperparameters_folder=os.path.join('.', 'experimental_files'),\n",
    "                             new_hyperopt=1, max_evals=1500,\n",
    "                             experiment_id=None):\n",
    "\n",
    "    if not os.path.exists(path_hyperparameters_folder):\n",
    "        os.makedirs(path_hyperparameters_folder)\n",
    "    if experiment_id is None:\n",
    "        experiment_id = datetime.now().strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "    else:\n",
    "        experiment_id = experiment_id\n",
    "    trials_file_name = 'DNN_hyperparameters_SP500_15m_try3'\n",
    "    trials_file_path = os.path.join(path_hyperparameters_folder, trials_file_name)\n",
    "    if new_hyperopt:\n",
    "        trials = Trials()\n",
    "    else:\n",
    "        trials = pc.load(open(trials_file_path, \"rb\"))\n",
    "    # n_exogenous_inputs = len(df.columns) - 1\n",
    "    space = _build_space()\n",
    "\n",
    "    fmin_objective = partial(_hyperopt_objective, trials=trials, trials_file_path=trials_file_path,\n",
    "                             max_evals=max_evals)\n",
    "    fmin(fmin_objective, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55eb50b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "55eb50b1",
    "outputId": "ca5ac3a3-b889-4710-df9d-7a0b3409d29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date  VALUE_LT_STA3\n",
      "0       2021-06-15 09:30:00           24.6\n",
      "1       2021-06-15 09:40:00           24.8\n",
      "2       2021-06-15 09:50:00           25.0\n",
      "3       2021-06-15 10:00:00           25.1\n",
      "4       2021-06-15 10:10:00           25.4\n",
      "...                     ...            ...\n",
      "109948  2023-07-18 23:20:00           19.3\n",
      "109949  2023-07-18 23:30:00           19.4\n",
      "109950  2023-07-18 23:40:00           19.6\n",
      "109951  2023-07-18 23:50:00           19.8\n",
      "109952  2023-07-19 00:00:00           19.8\n",
      "\n",
      "[109953 rows x 2 columns]\n",
      "                      Date  month  minute  hour\n",
      "0      2021-06-15 09:30:00      6      30     9\n",
      "1      2021-06-15 09:40:00      6      40     9\n",
      "2      2021-06-15 09:50:00      6      50     9\n",
      "3      2021-06-15 10:00:00      6       0    10\n",
      "4      2021-06-15 10:10:00      6      10    10\n",
      "...                    ...    ...     ...   ...\n",
      "108848 2023-07-11 08:00:00      7       0     8\n",
      "108849 2023-07-11 08:10:00      7      10     8\n",
      "108850 2023-07-11 08:20:00      7      20     8\n",
      "108851 2023-07-11 08:30:00      7      30     8\n",
      "108852 2023-07-11 08:40:00      7      40     8\n",
      "\n",
      "[108853 rows x 4 columns]\n",
      "train 107848\n",
      "                       Date  VALUE_LT_STA3\n",
      "0       2021-06-15 09:30:00           24.6\n",
      "1       2021-06-15 09:40:00           24.8\n",
      "2       2021-06-15 09:50:00           25.0\n",
      "3       2021-06-15 10:00:00           25.1\n",
      "4       2021-06-15 10:10:00           25.4\n",
      "...                     ...            ...\n",
      "109948  2023-07-18 23:20:00           19.3\n",
      "109949  2023-07-18 23:30:00           19.4\n",
      "109950  2023-07-18 23:40:00           19.6\n",
      "109951  2023-07-18 23:50:00           19.8\n",
      "109952  2023-07-19 00:00:00           19.8\n",
      "\n",
      "[109953 rows x 2 columns]\n",
      "                      Date  month  minute  hour\n",
      "107853 2023-07-04 10:10:00      7      10    10\n",
      "107854 2023-07-04 10:20:00      7      20    10\n",
      "107855 2023-07-04 10:30:00      7      30    10\n",
      "107856 2023-07-04 10:40:00      7      40    10\n",
      "107857 2023-07-04 10:50:00      7      50    10\n",
      "...                    ...    ...     ...   ...\n",
      "109948 2023-07-18 23:20:00      7      20    23\n",
      "109949 2023-07-18 23:30:00      7      30    23\n",
      "109950 2023-07-18 23:40:00      7      40    23\n",
      "109951 2023-07-18 23:50:00      7      50    23\n",
      "109952 2023-07-19 00:00:00      7       0     0\n",
      "\n",
      "[2100 rows x 4 columns]\n",
      "val 1095\n",
      "\titers: 100, epoch: 1 | loss: 0.0103040\n",
      "\tspeed: 0.3616s/iter; left time: 1949768.0724s\n",
      "\titers: 200, epoch: 1 | loss: 0.0066191\n",
      "\tspeed: 0.3552s/iter; left time: 1914990.4815s\n",
      "\titers: 300, epoch: 1 | loss: 0.0093090\n",
      "\tspeed: 0.3549s/iter; left time: 1913662.2844s\n",
      "\titers: 400, epoch: 1 | loss: 0.0142047\n",
      "\tspeed: 0.3564s/iter; left time: 1921333.9727s\n",
      "\titers: 500, epoch: 1 | loss: 0.0110761\n",
      "\tspeed: 0.3551s/iter; left time: 1914719.3958s\n",
      "\titers: 600, epoch: 1 | loss: 0.0040379\n",
      "\tspeed: 0.3557s/iter; left time: 1917503.2108s\n",
      "\titers: 700, epoch: 1 | loss: 0.0105351\n",
      "\tspeed: 0.3561s/iter; left time: 1919966.0760s\n",
      "\titers: 800, epoch: 1 | loss: 0.0075371\n",
      "\tspeed: 0.3558s/iter; left time: 1917996.8544s\n",
      "\titers: 900, epoch: 1 | loss: 0.0045010\n",
      "\tspeed: 0.3560s/iter; left time: 1919337.7342s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0154621\n",
      "\tspeed: 0.3561s/iter; left time: 1919921.1656s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0041809\n",
      "\tspeed: 0.3560s/iter; left time: 1918903.4613s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b60420a41469>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath_hyperparameters_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./experimental_files/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m hyperparameter_optimizer(path_hyperparameters_folder=path_hyperparameters_folder,\n\u001b[0m\u001b[1;32m      6\u001b[0m                          \u001b[0mnew_hyperopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_hyperopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                          experiment_id=experiment_id)#0.0814 di mae nell'articolo#0.0145(0.0037) MSE'''\n",
      "\u001b[0;32m<ipython-input-8-444ee812b9ee>\u001b[0m in \u001b[0;36mhyperparameter_optimizer\u001b[0;34m(path_hyperparameters_folder, new_hyperopt, max_evals, experiment_id)\u001b[0m\n\u001b[1;32m     64\u001b[0m     fmin_objective = partial(_hyperopt_objective, trials=trials, trials_file_path=trials_file_path,\n\u001b[1;32m     65\u001b[0m                              max_evals=max_evals)\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmin_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-444ee812b9ee>\u001b[0m in \u001b[0;36m_hyperopt_objective\u001b[0;34m(hyperparameters, trials, trials_file_path, max_evals)\u001b[0m\n\u001b[1;32m     19\u001b[0m                      )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mforecaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mYp_mean\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mforecaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5983b6d4adcc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba10e42ca8b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mdec_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dec_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mark_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mdec_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_self_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# De-normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba10e42ca8b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, cross, x_mask, cross_mask, tau, delta)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba10e42ca8b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, cross, x_mask, cross_mask, tau, delta)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         x = x + self.dropout(self.self_attention(\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba10e42ca8b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, queries, keys, values, attn_mask, tau, delta)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         out, attn = self.inner_attention(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba10e42ca8b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, queries, keys, values, attn_mask, tau, delta)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTriangularCausalMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba10e42ca8b1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, B, L, device)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mmask_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_hyperopt = 1#0.0065117\n",
    "experiment_id = 1\n",
    "max_evals = 1\n",
    "path_hyperparameters_folder = \"./experimental_files/\"\n",
    "hyperparameter_optimizer(path_hyperparameters_folder=path_hyperparameters_folder,\n",
    "                         new_hyperopt=new_hyperopt, max_evals=max_evals,\n",
    "                         experiment_id=experiment_id)#0.0814 di mae nell'articolo#0.0145(0.0037) MSE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15821836",
   "metadata": {
    "id": "15821836"
   },
   "outputs": [],
   "source": [
    "def MAE(pred, true):\n",
    "    return np.mean(np.abs(pred - true))\n",
    "\n",
    "\n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred - true) ** 2)\n",
    "\n",
    "\n",
    "def RMSE(pred, true):\n",
    "    return np.sqrt(MSE(pred, true))\n",
    "\n",
    "\n",
    "def MAPE(pred, true):\n",
    "    return np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "def MSPE(pred, true):\n",
    "    return np.mean(np.square((pred - true) / true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c9769",
   "metadata": {
    "id": "201c9769"
   },
   "outputs": [],
   "source": [
    "label_len=200\n",
    "seq_len=450\n",
    "pred_len=6\n",
    "forecaster = DNNModel(batch_size=1)\n",
    "setting = '{}'.format('EMANUELE')\n",
    "Yp_mean ,Y_test= forecaster.vali_test(setting, test=True)\n",
    "data=Dataset(flag='val',size=[seq_len,label_len,pred_len],freq='10m')\n",
    "\n",
    "mae_validation = np.mean(MAE(Yp_mean, Y_test))\n",
    "mse_validation = np.mean(MSE(Yp_mean, Y_test))\n",
    "smape_validation = np.mean(MAPE(Y_test, Yp_mean))*100\n",
    "print(\"MAE: {:.3f} | MAPE: {:.6f} % | MSE: {:.6f}\".format(mae_validation, smape_validation,mse_validation))\n",
    "Y_test = data.inverse_transform(Y_test.reshape(-1, 1)).flatten()\n",
    "Yp_mean = data.inverse_transform(Yp_mean.reshape(-1, 1)).flatten()\n",
    "mae_validation = np.mean(MAE(Yp_mean, Y_test))\n",
    "mse_validation = np.mean(MSE(Yp_mean, Y_test))\n",
    "smape_validation = np.mean(MAPE(Y_test, Yp_mean))*100\n",
    "time = range(len(Y_test))\n",
    "print(\"MAE: {:.3f} | MAPE: {:.4f} % | MSE: {:.4f}\".format(mae_validation, smape_validation,mse_validation))\n",
    "plt.plot(time, Y_test.flatten(), color='blue', label='Prezzi Veri')\n",
    "plt.plot(time, Yp_mean.flatten(), color='red', label='Previsioni')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Temperaure')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "differenza=np.abs(Yp_mean-Y_test).flatten()\n",
    "time = range(len(differenza))\n",
    "plt.plot(time, differenza, label='previsione-vero')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('previsione-vero')\n",
    "plt.title('previsione-vero')\n",
    "plt.show()\n",
    "difference=(Yp_mean-Y_test).flatten()\n",
    "plt.figure(figsize=(10,5),dpi=100)\n",
    "plt.hist(difference,bins=100)\n",
    "plt.show()\n",
    "print(\"media istogramma\",np.mean(difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XnAW1A1UyL7w",
   "metadata": {
    "id": "XnAW1A1UyL7w"
   },
   "outputs": [],
   "source": [
    "label_len=6\n",
    "seq_len=1000\n",
    "pred_len=6\n",
    "forecaster = DNNModel(batch_size=1)\n",
    "setting = '{}'.format('EMANUELE')\n",
    "Yp_mean ,Y_test= forecaster.vali_test(setting, test=True)\n",
    "Yp_mean =Yp_mean[:,-1,0]\n",
    "Y_test=Y_test[:,-1,0]\n",
    "data=Dataset(flag='val',size=[seq_len,label_len,pred_len],freq='10m')\n",
    "mae_validation = np.mean(MAE(Yp_mean, Y_test))\n",
    "mse_validation = np.mean(MSE(Yp_mean, Y_test))\n",
    "smape_validation = np.mean(MAPE(Y_test, Yp_mean))*100\n",
    "print(\"MAE: {:.3f} | MAPE: {:.6f} % | MSE: {:.6f}\".format(mae_validation, smape_validation,mse_validation))\n",
    "Y_test = data.inverse_transform(Y_test.reshape(-1, 1)).flatten()\n",
    "Yp_mean = data.inverse_transform(Yp_mean.reshape(-1, 1)).flatten()\n",
    "mae_validation = np.mean(MAE(Yp_mean, Y_test))\n",
    "mse_validation = np.mean(MSE(Yp_mean, Y_test))\n",
    "smape_validation = np.mean(MAPE(Y_test, Yp_mean))*100\n",
    "time = range(len(Y_test))\n",
    "print(\"MAE: {:.3f} | MAPE: {:.4f} % | MSE: {:.4f}\".format(mae_validation, smape_validation,mse_validation))\n",
    "plt.plot(time, Y_test.flatten(), color='blue', label='Prezzi Veri')\n",
    "plt.plot(time, Yp_mean.flatten(), color='red', label='Previsioni')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Temperaure')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "differenza=np.abs(Yp_mean-Y_test).flatten()\n",
    "time = range(len(differenza))\n",
    "plt.plot(time, differenza, label='previsione-vero')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('previsione-vero')\n",
    "plt.title('previsione-vero')\n",
    "plt.show()\n",
    "difference=(Yp_mean-Y_test).flatten()\n",
    "plt.figure(figsize=(10,5),dpi=100)\n",
    "plt.hist(difference,bins=100)\n",
    "plt.show()\n",
    "print(\"media istogramma\",np.mean(difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5fdd4",
   "metadata": {
    "id": "f7a5fdd4"
   },
   "outputs": [],
   "source": [
    "print(Yp_mean[:,-1,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd583c",
   "metadata": {
    "id": "9fbd583c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a523a16",
   "metadata": {
    "id": "1a523a16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed8843",
   "metadata": {
    "id": "98ed8843"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e21d4",
   "metadata": {
    "id": "c16e21d4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b9158",
   "metadata": {
    "id": "032b9158"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572829dd",
   "metadata": {
    "id": "572829dd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
